%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if
                                                          % you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.

%In case you encounter the following error:
%Error 1010 The PDF file may be corrupt (unable to open PDF file) OR
%Error 1000 An error occurred while parsing a contents stream. Unable to analyze the PDF file.
%This is a known problem with pdfLaTeX conversion filter. The file cannot be opened with acrobat reader
%Please use one of the alternatives below to circumvent this error by uncommenting one or the other
%\pdfobjcompresslevel=0
%\pdfminorversion=4

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
\usepackage{graphics} % for pdf, bitmapped graphics files
\usepackage{epsfig} % for postscript graphics files
\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
\usepackage{amsmath} % assumes amsmath package installed
\usepackage{amssymb}  % assumes amsmath package installed
%\usepackage{algorithmicx}
%\usepackage[Algorithm,ruled]{algorithm}
%\usepackage{algpseudocode}
\usepackage{tabularx}
\usepackage{multirow}
\usepackage{color}
\usepackage{url}
%\usepackage{balance}
\usepackage{subcaption}
\usepackage{breqn}
\usepackage{algorithm2e}
\usepackage{dblfloatfix} 
\usepackage[export]{adjustbox}
\usepackage{tabulary,booktabs}
%\usepackage{verbatim}
%\usepackage{flushend}

\newcommand{\junk}[1]{}
\newcommand{\abs}[1]{\left| #1 \right|} %| |
\newcommand{\comment}[1]{\textcolor{red}{#1}}



\title{\LARGE \bf
Question 1 â€“ Loco-Manipulation Task
}

\author{Ahmed Adamjee$^{1}$ Abdulbaasit Sanusi$^{1}$ Kennedy Dike$^{1}$ % <-this % stops a space
\thanks{$^{1}$Department of Computer Science, University College London, Gower Street, WC1E 6BT, UK.
{\tt\small
{{ahmed.adamjee.21}@ucl.ac.uk}
{{abdulbaasit.sanusi.21}@ucl.ac.uk}
{{ikedinaekpere.dike.21}@ucl.ac.uk}
}}}


\date{09 March 2022} %it will not be displayed

\begin{document}

\maketitle
\thispagestyle{empty}
\pagestyle{empty}

% \begin{abstract}
% This is an example template for the Overleaf documentation.
% \end{abstract}

% \subtitle{\bf
% COMP0129: Example Overleaf Document
% }

\section*{PART I}
In order to complete this task, each of the robots would be attached with an IMU sensor in order to measure the velocity of the robot. A pressure sensor would also be attached to the end-effectors of the two manipulators. This is to enable the robots realise when it has gripped any of the debris. In order to save time and increase accuracy, the two robots would be attached with two different types of cameras as the tasks of the robot would be slightly different. One of the robots, Robot A, would be attached with a RBG-D camera while the other robot, Robot B, would be attached with a ToF camera. This means that Robot A and Robot B would be in constant communications with each other by sharing the visual data observed from their respective sensors. 
To begin the task, Robot A would use its RBG-D camera to provide a 3D map of its environment and localise the table via deep learning algorithms. The locations of the tables are thereafter shared with Robot B and the two robots move, with a constant speed measured by the IMU sensor, to one of the tables. Once the two robots are close to a particular table, Robot B uses its ToF camera to identify the location of the debris on the table by using deep learning algorithms to differentiate between the debris and the table. The use of the Tof camera here as they offer better accuracy in short distances compared to the RBG-D cameras. Once the positions of the debris is identified, it is shared with Robot A. Robot B first picks a debris and heads over to the other table to place it and Robot A does the same as it now knows the position of the debris.

\section*{PART II}
As time is not a factor in this situation, the tasks of the two robots would be split into 2 functions: a) mapping and localisation and b) pick and place functions. Robot A would be attached with both an RBG-D camera,to map the entire environment, and a ToF camera to differentiate between the debris and the table. Robot B would attached with just a pressure sensor in the end effector as its duties is just to pick the debris from one table and place it on the other table. Similar to Part I, Robot A would first use the RBG-D camera to map the environment and localise the table. Robot A then also finds the table containing the debris and share both the location of the two tables but also the location of the debris with Robot B. Robot B the approach the table containig the debris and picks it up and places the debris in the other table. Robot B repeats this process until no debris remains

\bibliographystyle{IEEEtran}
\bibliography{references}
\end{document}